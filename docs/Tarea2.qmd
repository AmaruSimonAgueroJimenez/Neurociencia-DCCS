---
title: "Tarea 2"
author: "Generaci√≥n 2025 DCCS"
date: "`r Sys.Date()`"
lang: es
format:
  html:
    smooth-scroll: true
    toc: true
    toc-depth: 6
    toc-location: right
    number-sections: true
    number-depth: 6
    code-fold: true
    bibliography: ref.bib
    csl: apa-numeric-superscript.csl
    fig-cap-location: bottom
#    css: styles.css
execute:
  python: true
  warning: false
  message: false
  fig-width: 8
  fig-height: 6
---

<img src="logo1.png" style="width: 250px; position:relative; top:0; left:0; padding:10px;"/> <img src="logo2.png" style="width: 400px; position:relative; top:0; right:0; padding:10px;"/>

# Paquetes necesarios

```{r}
install_and_load <- function(package) {
  if (!require(package, character.only = TRUE)) {
    utils::install.packages(package)
    library(package, character.only = TRUE)
  }
}

packages <- c("tidyverse", "runjags", "rjags", "loo", "coda", "lme4", "rstatix","knitr","kableExtra", "scales","patchwork")

invisible(capture.output(sapply(packages, install_and_load)))
```

# Datos task Go NoGo

| Variables | Descripci√≥n                                    |
|-----------|------------------------------------------------|
| rt        | Reaction time (in milliseconds)                |
| est       | Stimulus type: 1 = Go, 2 = NoGo                |
| resp      | Response, -99 indicates no response            |
| laten     | Onset of stimulus (in milliseconds)            |
| good      | Recording accuracy: 1 = correct, 0 = incorrect |
| SU        | Participant ID                                 |

## Visualizaci√≥n de los datos

```{r}
data <- read.table(paste0(gsub("/docs", "", getwd()), "/data/Behavioral_GNG.csv"), header=TRUE, sep=",")
  
kable(head(data,10)) %>%
  kable_styling("striped", full_width = F)
```

```{r}
data <- data %>%
  group_by(SU) %>%
  arrange(X, .by_group = TRUE) %>%  # Ordena por latencia ascendente dentro de cada sujeto
  mutate(trial_num = row_number()) %>% 
  ungroup %>%
  mutate(est_label = ifelse(est == 1, "Go", "No Go")) %>% 
  mutate(resp_label = ifelse(resp == -99, "No Respuesta", "Respuesta"))

ggplot(data, aes(x = trial_num, fill = est_label, color = est_label)) +
  geom_histogram(position = "identity", alpha = 0.1, bins = 400) +
  scale_fill_manual(values = c("Go" = "green", "No Go" = "red")) +
  scale_color_manual(values = c("Go" = "green", "No Go" = "red")) +
  labs(
    title = "Aparici√≥n de Go y No Go en la secuencia de ensayos",
    x = "Posici√≥n del ensayo (trial_num)",
    y = "Frecuencia",
    fill = "Tipo de ensayo",
    color = "Tipo de ensayo"
  ) +
  theme_minimal()
```

```{r}
#| eval: false
#| include: false
ggplot(data, aes(x = trial_num, fill = resp_label)) +
  geom_bar(position = "fill") +
  facet_wrap(~ est_label) +
  labs(title = "Proporci√≥n de respuestas por n√∫mero de ensayo y tipo",
       x = "N√∫mero de ensayo",
       y = "Proporci√≥n",
       fill = "Tipo de respuesta") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1")
```

```{r}
# 1) contar y completar combinaciones que falten
data_area <- data %>%
  count(trial_num, est_label, resp_label) %>%                  # cuenta n por combinaci√≥n
  complete(trial_num, est_label, resp_label, fill = list(n=0)) %>%  # mete los que falten con n=0
  group_by(trial_num, est_label) %>%
  mutate(prop = n / sum(n)) %>%                                # calcula proporci√≥n
  ungroup() %>%
  mutate(trial_num = as.integer(trial_num))                    # fuerza tipo num√©rico

# 2) dibujar el √°rea apilada
ggplot(data_area, aes(x = trial_num,
                      y = prop,
                      fill = resp_label,
                      group = resp_label)) +                    # agrupa por categor√≠a
  geom_area(position = "stack", alpha = 0.7) +                 # apilado expl√≠cito
  facet_wrap(~ est_label)  +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  scale_fill_brewer(palette = "Set1") +
  labs(
    title = "Proporci√≥n de respuestas por n√∫mero de ensayo y tipo (√°rea)",
    x     = "N√∫mero de ensayo",
    y     = "Proporci√≥n",
    fill  = "Tipo de respuesta"
  ) +
  theme_minimal()
```

```{r}
ggplot(data %>% filter(est_label == "Go" & rt > 0),
       aes(x = as.integer(trial_num), y = rt)) +
  stat_summary(fun = mean,      geom = "line",  size = 0.1) +
  stat_summary(fun.data = mean_cl_normal,
               geom = "ribbon", alpha = 0.2)  +
  labs(
    title = "Tiempo medio de respuesta (Go) por ensayo",
    x     = "N√∫mero de ensayo",
    y     = "RT medio (ms)"
  ) +
  theme_minimal()
```

# Trial Go-NoGo

```{r}
data <- data %>% group_by(SU) %>%
  group_by(SU) %>% 
  arrange(trial_num) %>% 
  mutate(
    new_trial = 1 + cumsum(
      lag(est_label == "No Go",
          default = FALSE)
    )
  ) %>% 
  ungroup() %>% 
  group_by(SU, new_trial) %>% 
  mutate(
    new_trial_num = row_number()
  ) 

ggplot(data %>% filter(est_label == "Go" & rt > 0),
       aes(x = as.integer(new_trial_num), y = rt)) +
  geom_line(aes(group = interaction(SU,new_trial)), alpha = 0.1) +
  labs(
    title = "Tiempo medio de respuesta (Go) por Trial Go-NoGo",
    x     = "N√∫mero de ensayo por sujeto (Trial Go-NoGo)",
    y     = "RT medio (ms)"
  ) +
  theme_minimal() +
  facet_wrap(~ SU, scale="free_y")

ggplot(data %>% filter(est_label == "Go" & rt > 0),
       aes(x = as.integer(new_trial_num), y = rt)) +
  geom_line(aes(group = interaction(SU,new_trial)), alpha = 0.1) +
  geom_smooth(aes(group = SU),method = "lm", se = FALSE, color = "blue", alpha =0.5) +
  labs(
    title = "Tiempo medio de respuesta (Go) por Trial Go-NoGo",
    x     = "N√∫mero de ensayo por sujeto (Trial Go-NoGo)",
    y     = "RT medio (ms)"
  ) +
  theme_minimal() +
  facet_wrap(~ SU, scale="free_y")
```

```{r}
dat_raw <- read.table(paste0(gsub("/docs", "", getwd()), "/data/Behavioral_GNG.csv"), header=TRUE, sep=",")
dat <- dat_raw %>% 
    mutate(
        resp = if_else(resp == -99, NA_real_, resp),
        rt = if_else(resp == -99, NA_real_, rt),
        no_go_flag = if_else(est == 2, 1, 0)
    ) %>% 
    group_by(SU) %>% 
    mutate(
        trial = as.factor(cumsum(no_go_flag)),
        trial_num = as.numeric(as.character(trial))
    ) %>% 
    ungroup() %>% 
    group_by(SU, trial) %>% 
    mutate(
        trial_len = row_number()
    )
# dat

# model betas ----

betas <- dat %>% 
    filter(!is.na(rt)) %>% 
    ungroup() %>% 
    group_by(SU, trial) %>% 
    group_split() %>% 
    map_dfr(., function(X){
        mdl <- lm(rt ~ trial_len, data = X)
        mdl_coef <- tibble(
            intercept = coef(mdl)[1],
            beta      = coef(mdl)[2],
            SU        = X$SU[1],
            trial     = X$trial[1]
        )
        return(mdl_coef)
    })

# lmer rt mdl ----

rt_mdl <- lmerTest::lmer(
    data = dat,
    log(rt) ~ trial_len + (trial_len|SU)
)
summary(rt_mdl)


rt_mdl_emm <- emmeans::emmeans(
    rt_mdl,
    ~ trial_len,
    type = "response",
    at = list(trial_len = seq(1, 8, 1))
)
rt_mdl_emm

# beta mdl ----

rt_beta_mdl <- lme4::glmer(
    data = dat,
    rt ~ trial_len + (trial_len | SU),
    family = Gamma(link = "log")
)
summary(rt_beta_mdl)

rt_beta_emm <- emmeans::emmeans(
    rt_beta_mdl,
    ~ trial_len,
    type = "response",
    at = list(trial_len = seq(1, 8, 1))
)
rt_beta_emm

# beta mdl consider trial position ----

rt_beta_trial_mdl <- lme4::glmer(
    data = dat %>%
        group_by(SU) %>% 
        mutate(
        trial_len = scales::rescale(trial_len, to = c(0, 1)),
        trial_num = scales::rescale(trial_num, to = c(0, 1))
    ),
    rt ~ trial_len * trial_num + (trial_len | SU) + (1 | trial_num),
    family = Gamma(link = "log")
)
summary(rt_beta_trial_mdl)

rt_beta_trial_emm <- emmeans::emmeans(
    rt_beta_trial_mdl,
    ~ trial_len | trial_num,
    type = "response",
    at = list(trial_len = seq(0, 1, 0.25),
              trial_num = seq(0, 1, 0.25))
)
rt_beta_trial_emm


# plots ----
p1 <- dat %>% 
    filter(!is.na(rt)) %>% 
    ggplot(aes(
        trial_len, rt
    )) +
    geom_point(aes(group = interaction(SU, trial))) +
    geom_smooth(method = "lm", se = FALSE, aes(group = interaction(SU, trial)),
                alpha = 0.25, color = "gray", linewidth = 0.5) +
    geom_smooth(method = "lm", se = FALSE, aes(group = SU),
                alpha = 1, color = "black") +
    facet_wrap(~SU, scale = "free_y") +
    theme_classic()
p1

p2 <- betas %>% 
    ggplot(aes(
        as.factor(SU), beta
    )) +
    geom_violin() +
    geom_point(size = 1.5, shape = 21) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    ggpubr::theme_classic2()
p2

p3 <- betas %>% 
    ggplot(aes(
        beta
    )) +
    geom_density() +
    geom_vline(xintercept = 0, linetype = "dashed") +
    ggpubr::theme_classic2()
p3

p4 <- rt_mdl_emm %>% 
    broom.mixed::tidy(., conf.int = TRUE) %>% 
    ggplot(aes(
        trial_len, response
    )) +
    geom_line() +
    geom_ribbon(aes(ymin = conf.low, ymax = conf.high),
                alpha = 0.25) +
    ggpubr::theme_classic2()
p4

p5 <- rt_beta_emm %>% 
    broom.mixed::tidy(., conf.int = TRUE) %>% 
    ggplot(aes(
        trial_len, response
    )) +
    geom_line() +
    geom_ribbon(aes(ymin = conf.low, ymax = conf.high),
                alpha = 0.25) +
    ggpubr::theme_classic2()
p5

## rt over go's and trials ----
p6_dat <- dat %>%
        group_by(SU) %>% 
        mutate(
        trial_len = scales::rescale(trial_len, to = c(0, 1)),
        trial_num = scales::rescale(trial_num, to = c(0, 1)),
        bin_trial_num = ntile(trial_num, 5)
    )

p6 <- rt_beta_trial_emm %>% 
    broom.mixed::tidy(., conf.int = TRUE) %>% 
    ggplot(aes(
        trial_len, response, group = trial_num
    )) +
    geom_line() +
    geom_ribbon(aes(ymin = conf.low, ymax = conf.high),
                alpha = 0.1, fill = "gray") +
    ggpubr::theme_classic2() +
    facet_wrap(~trial_num)
p6

p7 <- rt_beta_trial_emm %>% 
    broom.mixed::tidy(., conf.int = TRUE) %>% 
    ggplot(aes(
        trial_num, response
    )) +
    geom_line(linewidth = 3, aes(group = trial_len, color = trial_len)) 
p7

p8 <- p6_dat %>% 
    drop_na() %>% 
    group_by(SU, bin_trial_num) %>% 
    summarise(
        rt = mean(rt)
    ) %>% 
    ggplot(aes(
        bin_trial_num, rt
    )) +
    stat_summary(
        fun.data = "mean_se",
        geom = "pointrange",
        color = "purple",
        aes(group = bin_trial_num)
    ) +
    stat_summary(
        fun.data = "mean_se",
        geom = "line",
        color = "purple"
    ) +
    geom_boxplot(aes(group = as.factor(bin_trial_num)),
                fill = NA, trim = TRUE, outlier.shape = NA)
p8
```

```{r}
ggplot(
  data %>% filter(est_label == "Go" & rt > 0),
  aes(x = rt)
) +
  geom_histogram() +
  labs(
    title = "Tiempo medio de respuesta (Go) por Trial Go-NoGo",
    x     = "RT (ms)",
    y     = "Frecuencia"
  ) +
  theme_minimal() +
  facet_wrap(~ SU, scales = "free")
```

```{r}
ggplot2::ggplot(
  data %>% filter(est_label == "Go" & rt > 0) %>% 
    filter(!is.na(rt) & !is.na(trial_num)),
  ggplot2::aes(x = trial_num, y = rt)
) +
  ggplot2::geom_point(alpha = 0.4, size = 1) +
  ggplot2::labs(
    title = "RT vs Trial Number por Sujeto",
    x     = "N√∫mero de Trial",
    y     = "Tiempo de respuesta (ms)"
  ) +
  ggplot2::theme_minimal() +
  ggplot2::facet_wrap(~ SU, scales = "free_y")
```

```{r}
ggplot2::ggplot(
  data %>% filter(est_label == "Go" & rt > 0) %>% 
    filter(!is.na(rt) & !is.na(trial_num)),
  ggplot2::aes(x = trial_num, y = rt)
) +
  ggplot2::geom_point(alpha = 0.4, size = 1) +
  ggplot2::geom_smooth(method = "lm", se = FALSE, color = "blue") +
  ggplot2::labs(
    title = "RT vs Trial Number por Sujeto",
    x     = "N√∫mero de Trial",
    y     = "Tiempo de respuesta (ms)"
  ) +
  ggplot2::theme_minimal() +
  ggplot2::facet_wrap(~ SU, scales = "free_y")
```

# Estimaci√≥n del Aprendizaje de la Probabilidad de Go en una Tarea Go/No-Go

## Objetivo

Estimar c√≥mo los sujetos aprenden la probabilidad de aparici√≥n del est√≠mulo **Go** (`P(Go)`) en una tarea Go/No-Go, utilizando como variable de inter√©s el **tiempo de respuesta (RT)** a los est√≠mulos Go.

------------------------------------------------------------------------

## Codificaci√≥n de Est√≠mulos y Respuestas

-   üü¢ **Go** ‚Üí Acci√≥n esperada: **Apretar**
-   üî¥ **NoGo** ‚Üí Acci√≥n esperada: **Esperar**

------------------------------------------------------------------------

## Hip√≥tesis del Modelo

Se postula que los sujetos ajustan sus expectativas sobre la probabilidad de aparici√≥n del est√≠mulo **Go** a lo largo del tiempo. Esto se refleja conductualmente en los **RT**:

-   Si `P(Go)` ‚Üë ‚Üí `RT` ‚Üì\
-   Si `P(Go)` ‚Üì ‚Üí `RT` ‚Üë

------------------------------------------------------------------------

## Modelo de Aprendizaje por Predicci√≥n de Error

Los sujetos actualizan una estimaci√≥n interna de la probabilidad `Q_t` de que aparezca un est√≠mulo **Go** usando una regla tipo Rescorla-Wagner:

$$
\text{RPE}_t = R_t - Q_t
$$

$$
Q_{t+1} = Q_t + \alpha \cdot \text{RPE}_t
$$

Donde:

-   $R_t$: recompensa observada (1 si Go, 0 si NoGo)
-   $Q_t$: probabilidad esperada de Go
-   $\alpha$: tasa de aprendizaje (puede decrecer con el tiempo o mantenerse constante)

------------------------------------------------------------------------

## Pol√≠tica de Elecci√≥n: Funci√≥n Softmax

Se modela la probabilidad de emitir una respuesta con una pol√≠tica tipo softmax, que transforma los valores $Q$ en probabilidades de acci√≥n:

$$
P(\text{respuesta}_t = \text{Go}) = \frac{e^{ Q_t/\tau}}{e^{ Q_t/\tau} + e^{ Q_{NoGo}/\tau}}
$$

-   $\tau$: par√°metro de temperatura (controla la exploraci√≥n vs. explotaci√≥n)
    -   Si $\tau \to \infty$: decisiones aleatorias (m√°xima exploraci√≥n)
    -   Si $\tau \to 0$: decisiones determin√≠sticas (m√°xima explotaci√≥n)

------------------------------------------------------------------------

## Tiempo de Respuesta como Funci√≥n del Valor

El tiempo de respuesta ($RT$) se modela como inversamente proporcional a la certeza sobre Go:

$$
RT_t = f(Q_t), \quad \frac{dRT_t}{dQ_t} < 0
$$

Opciones funcionales: 

- Lineal: $RT_t = a - b \cdot Q_t$ 
- Exponencial: $RT_t = a \cdot e^{-b \cdot Q_t}$

---

## Funci√≥n de Verosimilitud

El objetivo es encontrar los par√°metros $\alpha$ y $\tau$ que **maximicen la probabilidad** de la secuencia de elecciones observadas:

Para una sola acci√≥n en ensayo $t$, la verosimilitud est√° dada por la pol√≠tica Softmax:

$$
L_t = P(a_t \mid Q_t, \tau)
$$

La log-verosimilitud total sobre todos los ensayos es:

$$
\log L = \sum_t \log P(a_t \mid Q_t, \tau)
$$

## Procedimiento de Ajuste

1.  Elegir valores candidatos para $\alpha$ y $\tau$
2.  Inicializar $Q$ a 0.5
3.  Simular cada ensayo con actualizaci√≥n de $Q$ y c√°lculo de $P(a)$
4.  Calcular la log-verosimilitud total
5.  Optimizar los par√°metros con restricciones ($\alpha \in [0,1]$, $\tau > 0$)

---

## Interpretaci√≥n

-   Si $\alpha = 0$: el agente **no aprende**, los valores $Q$ permanecen constantes.
-   Si $\alpha > 0$ pero bajo, hay **aprendizaje lento**.
-   Si $\tau \to \infty$: decisiones aleatorias (m√°xima exploraci√≥n)
-   Si $\tau \to 0$: decisiones determin√≠sticas (m√°xima explotaci√≥n)

## An√°lisis y Visualizaci√≥n

Podemos usar simulaciones sobre los datos observados para interpretar si el patr√≥n de RT o de elecciones puede explicarse por este modelo:

-   Evoluci√≥n de $Q_t$ y $RT_t$ a trav√©s del tiempo
-   Relaci√≥n entre secuencias previas de Go/NoGo y variaciones de $RT$
-   Curvas de aprendizaje estimadas por sujeto
-   Ajuste del modelo mediante inferencia bayesiana o m√°xima verosimilitud

------------------------------------------------------------------------

## Resultado Esperado

-   A medida que el sujeto experimenta m√°s est√≠mulos Go, $Q_t$ aumenta, la probabilidad de respuesta tambi√©n aumenta, y $RT$ disminuye.
-   El modelo permite capturar c√≥mo el sujeto adapta su comportamiento a las contingencias probabil√≠sticas de la tarea.

------------------------------------------------------------------------
